# Summary

| Date   | Notes
| :----- | :-------------------------------
| 06/05 | Team meeting on week tasks. Re-read the two papers: Investigating Neural Network Architectures and Searching for Problematic Simulation Conditions
| 06/06 | Team meeting for updates on Twinmotion & UE work. Explored our datasets and how to navigate those.
| 06/07 | Finished fastai tutorial #2, created a custom UFO image classifier model and deployed it.
| 06/08 | Trained our 2ndRunHighRes dataset with the 4 chosen CNN models from the research paper and compared their accuracies in FastAI. Tried different data angmentation techniques thanks to the resources from Francisco's notes.
| 06/09 | Found that Resnet34 has the best performance and training time => deployed the model with resnet34 trained on 2ndRunHighRes dataset
| 06/11 | Started trying to rebuild models from the research paper with FastAI, starting with BasicClassification.py

# Activities 

# 1. Created a UFO vs stars image classifier model to practice with FastAI. 

* Following FastAi documentation and tutorials, I created the confusion matrix and cleaner to clean my data and improve models' performance. After that, I deployed the model using Gradio + HuggingFace. Here is the link to the live model: https://huggingface.co/spaces/chauhavu/ufo-model.
  <img width="800" alt="Screenshot 2023-06-12 at 3 44 08 PM" src="https://github.com/chauvuha/ARCS_Lab_Reports/assets/79251745/f4b96b61-0dba-4d26-b254-d86e68ac70c2">
  <img width="800" alt="Screenshot 2023-06-12 at 3 44 24 PM" src="https://github.com/chauvuha/ARCS_Lab_Reports/assets/79251745/4783c41d-637d-42b2-96cb-f4c8fb4dd367">
  <img width="800" alt="Screenshot 2023-06-12 at 3 44 46 PM" src="https://github.com/chauvuha/ARCS_Lab_Reports/assets/79251745/61b9ae93-3fcc-4623-bc4d-75bd73146e2a">
  
  <img width="800" alt="Screenshot 2023-06-12 at 3 42 48 PM" src="https://github.com/chauvuha/ARCS_Lab_Reports/assets/79251745/0984426a-166c-4653-a7d1-7e91d9071d6e">

# 2. Experimenting with current UE dataset (mostly data augmentation methods)(data/clark/data/2ndRunHighRes, OldenborgSmall-2022-07-11, Oldenborg-2022-07-01, and Office127-2022-07-0): 
   * I found that the Oldenborg-2022-07-01 dataset can be very helpful to test models since these are real pictures from oldenborg hallways.
   
   <img width="778" alt="Screenshot 2023-06-12 at 3 46 37 PM" src="https://github.com/chauvuha/ARCS_Lab_Reports/assets/79251745/61d1407f-2360-4acc-b0a5-4d87af348cfc">

   * I also explored data augmentation methods that are supported in FastAI's vision learner: RandomResizeCrop, Aug_transform, etc.
   * Only the 2ndRunHighRes data includes images with the same size. Therefore, we can use ImageDataLoaders for these:
  ```dls_train_2 = ImageDataLoaders.from_name_func('/data/clark/data/2ndRunHighRes', get_image_files('/data/clark/data/2ndRunHighRes'), filename_to_class, valid_pct=VALID_PCT, items_tfms=Resize(128))```
   * The other three datasets are not similar in size. If we want to use it, we have to use DataBlock to set the custom size.
    <img width="800" alt="Screenshot 2023-06-12 at 3 46 11 PM" src="https://github.com/chauvuha/ARCS_Lab_Reports/assets/79251745/69cdd49d-61aa-4739-9f29-cf78d75c5827">

# 3. Compared the CNN models from the research paper that FastAI Vision learner supports:
 * I compared the 4 models chosen the in paper Investigating Neural Network Architectures, Techniques, and Datasets for Autonomous Navigation in Simulation including: **resnet50, resnet34, alexnet, and resnet18**
 * I trained all 4 models on the ```data/clark/data/2ndRunHighRes``` dataset, and here are the results:

   <img width="800" alt="Screenshot 2023-06-12 at 3 47 35 PM" src="https://github.com/chauvuha/ARCS_Lab_Reports/assets/79251745/c3e96e54-bd06-4f7c-a349-29033d738e91">
   <img width="800" alt="Screenshot 2023-06-12 at 3 47 50 PM" src="https://github.com/chauvuha/ARCS_Lab_Reports/assets/79251745/09911e51-1a50-48b5-8a7a-8f5b7fa66dba">
   <img width="800" alt="Screenshot 2023-06-12 at 3 48 02 PM" src="https://github.com/chauvuha/ARCS_Lab_Reports/assets/79251745/22a1cb96-cb73-40a3-9829-16d380aa9b06">
   <img width="800" alt="Screenshot 2023-06-12 at 3 48 27 PM" src="https://github.com/chauvuha/ARCS_Lab_Reports/assets/79251745/a8f9fc9f-4ff1-4178-920c-36ffc636d8b6">


 * I found that **Resnet34** has the highest accuracy and deployed the this model to HuggingFace. Here is the link to the live model: https://huggingface.co/spaces/chauhavu/oldenborg-model.  I also included the sample test cases from the Oldenborg-2022-07-01 dataset. 
 
    <img width="800" alt="Screenshot 2023-06-12 at 3 49 15 PM" src="https://github.com/chauvuha/ARCS_Lab_Reports/assets/79251745/d483aaaf-ee07-4aa9-9364-c15151def84e">

# 4. Rebuilding Command+Image (ongoing)
* I have several questions to investigate:
    * I started with the BasicClassification.py. I explored the datasets and the pretrained models included in the file "uniform-full". This is my notebook after rebuilding the model and training with resnet18:
     <img width="800" alt="Screenshot 2023-06-12 at 11 34 11 PM" src="https://github.com/chauvuha/ARCS_Lab_Reports/assets/79251745/1335820e-fb8b-429f-a245-062e000bea24">
     <img width="800" alt="Screenshot 2023-06-12 at 11 35 46 PM" src="https://github.com/chauvuha/ARCS_Lab_Reports/assets/79251745/eaf01e51-944b-4889-a8ed-525105d78d5a">
     <img width="800" alt="Screenshot 2023-06-12 at 11 34 53 PM" src="https://github.com/chauvuha/ARCS_Lab_Reports/assets/79251745/7bff820c-2715-4667-bf4d-48d0c2be5e89">

# Issues

* This error indicates that all the images need to be of the same size so that the dls can run: 

  <img width="614" alt="Screenshot 2023-06-12 at 3 50 57 PM" src="https://github.com/chauvuha/ARCS_Lab_Reports/assets/79251745/e11665bc-a549-4d65-9d45-484916c5036e">

  => Solution: Use Datablock's Resize.

* How to view the pictures in a dataset models in macbook. Currently, the best way for me is just probably to put it into a datablock and then showbatch() because I had not found a good way to open it straight from shell commands.


* Check the number of batch for training and then for validation:

  ```num_valid_data = len(dls.valid.dataset)```

  ```num_train_data = len(dls.train.dataset)```

* The difference between ```learn.fine_tune()``` and ```learn.fit_one_cycle()```: If use_pretraining is set to True, the model will utilize pre-trained weights. Pre-trained models, such as ResNet18, have already been trained on a large dataset unrelated to the current dataset. So, we can use these learned weights as a starting point for the current task. Consequently, we will only perform fine-tuning using learn.fine_tune(). On the other hand, if the flag is False, we will train the model from scratch for the first time using cyclic learning rate scheduling without using any pre-trained weights, and we will do this with learn.fit_one_cycle(). This means that the model will rely solely on the training data provided through the data loaders (dls) to learn and improve its performance on the specific task at hand.

  <img width="286" alt="Screenshot 2023-06-12 at 3 49 40 PM" src="https://github.com/chauvuha/ARCS_Lab_Reports/assets/79251745/a9473f54-0489-4447-86d3-9cbac1293bdc">

* I ran into several problems with git and hugging face that are not covered in the tutorial, which I think mostly is because the tutorial just skipped the part where we had to modify the app.py file, and did not really tell where to put it. Here is the right steps to deploy.
    * Download the trained model in jupyter notebook as a .pkl file.
    * Created a HuggingFace space and clone it. Then open in VSCode.
    * Move the downloaded .pkl file into the open directory in VSCode.
    * Add a ```app.py``` file in the open directory in VSCode. Here is my full code in ```app.py``` for it to work:
   
      <img width="800" alt="Screenshot 2023-06-12 at 3 51 38 PM" src="https://github.com/chauvuha/ARCS_Lab_Reports/assets/79251745/324ff392-1920-4e93-b806-800954790124">

    *  Add requirement.txt file in the open directory in VSCode. The file includes two lines: fastai and scikit-image. This file is to specify the dependencies required for the project to run when deployed
       
    * The final file structure of my VSCode would look like this:
      
      <img width="171" alt="Screenshot 2023-06-12 at 3 52 03 PM" src="https://github.com/chauvuha/ARCS_Lab_Reports/assets/79251745/f1c7e4d7-0b0c-47ca-be91-e2cfb1eb0bdb">

     
    * If you want to add examples to the deployed model, you can add some pictures to the local directory (Here I added 'star.webp', 'ufo.webp', and 'star.webp').
    *  Run these commands in the terminal (These will help install lfs, which will take care of the .pkl file of our model)

          ```git lfs install```

          ```git lfs track "*.pkl"```

          ```git add .gitattributes```

          ``` git add .```

          ```git commit -am "let's deploy to huggingface spaces"```

          ``` git push```


* Run on one window at a time or else the memory will run out. 

# Plans
* Continue recreating the models with FastAI in the Investigating Neural Network Architectures, Techniques, and Datasets for Autonomous Navigation paper. 

  


