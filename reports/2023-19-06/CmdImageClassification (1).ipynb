{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b750317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.progress import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4496a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f39f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants \n",
    "VALID_PCT = 0.05\n",
    "NUM_REPLICATES = 1\n",
    "NUM_EPOCHS = 1\n",
    "# DATASET_DIR = Path(\"/data/clark/summer2021/datasets\")\n",
    "DATASET_DIR = Path(\"/data/clark/data/\")\n",
    "MODEL_PATH_REL_TO_DATASET = Path(\"cmd_models_fixed\")\n",
    "DATA_PATH_REL_TO_DATASET = Path(\"cmd_data_fixed\")\n",
    "VALID_MAZE_DIR = Path(\"../Mazes/validation_mazes8x8/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549d44d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "compared_models = {\n",
    "    \"resnet18\": resnet18\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab89b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_to_class(filename: str) -> str:\n",
    "    # Fixed the syntax to this can run on 2ndRunHighRes\n",
    "    return ((str(filename).split(\"_\")[0]).split('/')[-1])\n",
    "#     angle = float(str(filename).split(\"_\")[1].split(\".\")[0].replace(\"p\", \".\"))\n",
    "#     if angle > 0:\n",
    "#         return \"left\"\n",
    "#     elif angle < 0:\n",
    "#         return \"right\"\n",
    "#     else:\n",
    "#         return \"forward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdea72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageWithCmdDataset(Dataset):\n",
    "    def __init__(self, filenames):\n",
    "        \"\"\"\n",
    "        Creates objects for class labels, class indices, and filenames.\n",
    "        \n",
    "        :param filenames: (list) a list of filenames that make up the dataset\n",
    "        \"\"\"\n",
    "        self.class_labels = ['left', 'forward', 'right']\n",
    "        self.class_indices = {lbl:i for i, lbl in enumerate(self.class_labels)} # {'left': 0, 'forward': 1, 'right': 2}        \n",
    "        self.all_filenames = filenames\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Gives length of dataset.\n",
    "        \n",
    "        :return: (int) the number of filenames in the dataset\n",
    "        \"\"\"\n",
    "        return len(self.all_filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Gets the filename associated with the given index, opens the image at\n",
    "        that index, then uses the image's filename to get information associated\n",
    "        with the image such as its label and the label of the previous image.\n",
    "        \n",
    "        :param index: (int) number that represents the location of the desired data\n",
    "        :return: (tuple) tuple of all the information associated with the desired data\n",
    "        \"\"\"\n",
    "        # The filename of the image given a specific index\n",
    "        img_filename = self.all_filenames[index]            \n",
    "        \n",
    "        # Opens image file and ensures dimension of channels included\n",
    "        img = Image.open(img_filename).convert('RGB')\n",
    "        # Resizes the image\n",
    "        img = img.resize((224, 224))\n",
    "        # Converts the image to tensor and \n",
    "        img = torch.Tensor(np.array(img)/255)\n",
    "        # changes the order of the dimensions\n",
    "        img = img.permute(2,0,1)\n",
    "        \n",
    "        # Getting the current image's label\n",
    "        label_name = filename_to_class(img_filename)\n",
    "        label = self.class_indices[label_name]\n",
    "        \n",
    "        # Getting the previous image's label\n",
    "        # The default is 'forward'\n",
    "        cmd_name = 'forward'\n",
    "        \n",
    "        # If the index is not 0, the cmd is determined by the previous img_filename\n",
    "        if index != 0:\n",
    "            prev_img_filename = self.all_filenames[index-1]\n",
    "            cmd_name = filename_to_class(prev_img_filename)            \n",
    "        cmd = self.class_indices[cmd_name]\n",
    "        \n",
    "        # Data and the label associated with that data\n",
    "        return (img, cmd), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b29f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cmd_model(nn.Module):\n",
    "    def __init__(self, arch: str, pretrained: bool):\n",
    "        super(cmd_model, self).__init__()\n",
    "        self.cnn = arch(pretrained=pretrained)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.cnn.fc.out_features + 1, 512)\n",
    "        self.r1 = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(512, 3)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        img, cmd = data\n",
    "        x1 = self.cnn(img)\n",
    "        x2 = cmd.unsqueeze(1)\n",
    "        \n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.r1(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e240157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fig_filename(prefix: str, label: str, ext: str, rep: int) -> str:\n",
    "    fig_filename = f\"{prefix}-{label}-{rep}.{ext}\"\n",
    "    print(label, \"filename :\", fig_filename)\n",
    "    return fig_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa46459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloaders(dataset_name: str, prefix: str) -> DataLoaders:\n",
    "\n",
    "    path = DATASET_DIR / dataset_name\n",
    "    files = get_image_files(path)\n",
    "    \n",
    "    # Get size of dataset and corresponding list of indices\n",
    "    dataset_size = len(files)\n",
    "    dataset_indices = list(range(dataset_size))\n",
    "    \n",
    "    # Shuffle the indices\n",
    "    np.random.shuffle(dataset_indices)\n",
    "\n",
    "    # Get the index for where we want to split the data\n",
    "    val_split_index = int(np.floor(VALID_PCT * dataset_size))\n",
    "    \n",
    "    # Split the list of indices into training and validation indices\n",
    "    train_idx, val_idx = dataset_indices[val_split_index:], dataset_indices[:val_split_index]\n",
    "    \n",
    "    # Get the list of filenames for the training and validation sets\n",
    "    train_filenames = [files[i] for i in train_idx]\n",
    "    val_filenames = [files[i] for i in val_idx]\n",
    "    \n",
    "    # Create training and validation datasets\n",
    "    train_data = ImageWithCmdDataset(train_filenames)\n",
    "#     train_data.__get_item__(10)\n",
    "    val_data = ImageWithCmdDataset(val_filenames)\n",
    "    \n",
    "    # Get DataLoader\n",
    "    dls = DataLoaders.from_dsets(train_data, val_data)\n",
    "    dls = dls.cuda()\n",
    "\n",
    "    #dls.show_batch()  # type: ignore\n",
    "    plt.savefig(get_fig_filename(prefix, \"batch\", \"pdf\", 0))\n",
    "\n",
    "    return dls  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e121e0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    dls: DataLoaders,\n",
    "    model_arch: str,\n",
    "    pretrained: bool,\n",
    "    logname: Path,\n",
    "    modelname: Path,\n",
    "    prefix: str,\n",
    "    rep: int,\n",
    "):\n",
    "    arch = compared_models[model_arch]\n",
    "    net = cmd_model(arch, pretrained=pretrained)\n",
    "    \n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        net,\n",
    "        loss_func=CrossEntropyLossFlat(),\n",
    "        metrics=accuracy,\n",
    "        cbs=CSVLogger(fname=logname),\n",
    "    )\n",
    "\n",
    "    if pretrained:\n",
    "        learn.fine_tune(NUM_EPOCHS)\n",
    "    else:\n",
    "        learn.fit_one_cycle(NUM_EPOCHS)\n",
    "\n",
    "    # Save trained model\n",
    "    torch.save(net.state_dict(), modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3040f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    arg_parser = ArgumentParser(\"Train cmd classification networks.\")\n",
    "    arg_parser.add_argument(\n",
    "        \"model_arch\", help=\"Model architecture (see code for options)\"\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"dataset_name\", help=\"Name of dataset to use (corrected-wander-full)\"\n",
    "    )\n",
    "    arg_parser.add_argument(\n",
    "        \"--pretrained\", action=\"store_true\", help=\"Use pretrained model\"\n",
    "    )\n",
    "\n",
    "    args = arg_parser.parse_args()\n",
    "\n",
    "    # TODO: not using this (would require replacing first layer)\n",
    "    # rgb_instead_of_gray = True\n",
    "\n",
    "    # Make dirs as needed\n",
    "    model_dir = DATASET_DIR / args.dataset_name / MODEL_PATH_REL_TO_DATASET\n",
    "    model_dir.mkdir(exist_ok=True)\n",
    "    print(f\"Created model dir (or it already exists) : '{model_dir}'\")\n",
    "\n",
    "    data_dir = DATASET_DIR / args.dataset_name / DATA_PATH_REL_TO_DATASET\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "    print(f\"Created data dir (or it already exists)  : '{data_dir}'\")\n",
    "\n",
    "    file_prefix = \"classification-\" + args.model_arch\n",
    "    # file_prefix += \"-rgb\" if rgb_instead_of_gray else \"-gray\"\n",
    "    file_prefix += \"-pretrained\" if args.pretrained else \"-notpretrained\"\n",
    "    fig_filename_prefix = data_dir / file_prefix\n",
    "\n",
    "    dls = prepare_dataloaders(args.dataset_name, fig_filename_prefix)\n",
    "\n",
    "    # Train NUM_REPLICATES separate instances of this model and dataset\n",
    "    for rep in range(NUM_REPLICATES):\n",
    "        \n",
    "        model_filename = DATASET_DIR / args.dataset_name / MODEL_PATH_REL_TO_DATASET / f\"{file_prefix}-{rep}.pth\"\n",
    "        print(\"Model relative filename :\", model_filename)\n",
    "\n",
    "        # Checks if model exists and skip if it does (helps if this crashes)\n",
    "        if path.exists(model_filename):\n",
    "            continue\n",
    "\n",
    "        log_filename = DATASET_DIR / args.dataset_name / DATA_PATH_REL_TO_DATASET / f\"{file_prefix}-trainlog-{rep}.csv\"\n",
    "        print(\"Log relative filename   :\", log_filename)\n",
    "\n",
    "        train_model(\n",
    "            dls,\n",
    "            args.model_arch,\n",
    "            args.pretrained,\n",
    "            log_filename,\n",
    "            model_filename,\n",
    "            fig_filename_prefix,\n",
    "            rep,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707c70bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "py:light",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.14.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
